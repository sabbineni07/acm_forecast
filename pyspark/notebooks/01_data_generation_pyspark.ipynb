{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Cost Management Data Generation - PySpark Version\n",
        "\n",
        "This notebook generates sample Azure cost management data using PySpark for distributed processing.\n",
        "\n",
        "## Data Attributes\n",
        "- **SubscriptionGuid**: Unique subscription identifier\n",
        "- **ResourceGroup**: Azure resource group name\n",
        "- **ResourceLocation**: Geographic location of the resource (90% East US, 10% South Central US)\n",
        "- **UsageDateTime**: Timestamp of usage\n",
        "- **MeterCategory**: Category of the meter (Compute, Storage, Network, etc.)\n",
        "- **MeterSubCategory**: Sub-category of the meter\n",
        "- **MeterId**: Unique meter identifier\n",
        "- **MeterName**: Human-readable meter name\n",
        "- **MeterRegion**: Region where the meter applies\n",
        "- **UsageQuantity**: Amount of resource consumed\n",
        "- **ResourceRate**: Rate per unit of resource\n",
        "- **PreTaxCost**: Cost before taxes\n",
        "- **ConsumedService**: Service that consumed the resource\n",
        "- **ResourceType**: Type of Azure resource\n",
        "- **InstanceId**: Unique instance identifier\n",
        "- **Tags**: Key-value pairs for resource tagging\n",
        "- **OfferId**: Azure offer identifier\n",
        "- **AdditionalInfo**: Additional metadata\n",
        "- **ServiceInfo1/2**: Service-specific information\n",
        "- **ServiceName**: Name of the Azure service\n",
        "- **ServiceTier**: Tier of the service (Basic, Standard, Premium)\n",
        "- **Currency**: Currency code (USD only)\n",
        "- **UnitOfMeasure**: Unit of measurement for the resource\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "import uuid\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"AzureCostDataGeneration\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Set log level to reduce verbosity\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "print(\"PySpark session initialized successfully!\")\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "print(f\"Available cores: {spark.sparkContext.defaultParallelism}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
