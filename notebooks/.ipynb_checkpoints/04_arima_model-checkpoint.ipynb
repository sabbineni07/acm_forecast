{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARIMA Forecasting Model for Azure Cost Management\n",
        "\n",
        "This notebook implements ARIMA (AutoRegressive Integrated Moving Average) forecasting models for Azure cost prediction. ARIMA is a classical time series forecasting method that works well for stationary time series.\n",
        "\n",
        "## ARIMA Model Features\n",
        "- **AR (AutoRegressive)**: Uses past values to predict future values\n",
        "- **I (Integrated)**: Handles non-stationary data through differencing\n",
        "- **MA (Moving Average)**: Uses past forecast errors to predict future values\n",
        "- **Automatic Parameter Selection**: Uses statistical tests to find optimal parameters\n",
        "- **Seasonal ARIMA (SARIMA)**: Handles seasonal patterns\n",
        "\n",
        "## Objectives\n",
        "1. Load and prepare time series data for ARIMA\n",
        "2. Perform stationarity tests and transformations\n",
        "3. Find optimal ARIMA parameters using auto_arima\n",
        "4. Train ARIMA models for different cost categories\n",
        "5. Generate forecasts with confidence intervals\n",
        "6. Evaluate model performance and compare with Prophet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ARIMA specific imports\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from pmdarima import auto_arima\n",
        "from pmdarima.arima import ARIMA as PMDARIMA\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load forecasting data\n",
        "import pickle\n",
        "with open('/Users/sabbineni/projects/acm/data/forecasting_data.pkl', 'rb') as f:\n",
        "    forecasting_data = pickle.load(f)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Available time series: {list(forecasting_data.keys())}\")\n",
        "\n",
        "# Display data info\n",
        "for key, ts_data in forecasting_data.items():\n",
        "    print(f\"{key}: {len(ts_data)} data points, \"\n",
        "          f\"Date range: {ts_data.index.min()} to {ts_data.index.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stationarity Tests and Data Preparation\n",
        "def test_stationarity(timeseries, title=\"Time Series\"):\n",
        "    \"\"\"\n",
        "    Perform stationarity tests on time series data.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Stationarity Tests for {title} ===\")\n",
        "    \n",
        "    # ADF Test\n",
        "    adf_result = adfuller(timeseries.dropna())\n",
        "    print(f\"ADF Test:\")\n",
        "    print(f\"  ADF Statistic: {adf_result[0]:.6f}\")\n",
        "    print(f\"  p-value: {adf_result[1]:.6f}\")\n",
        "    print(f\"  Critical Values:\")\n",
        "    for key, value in adf_result[4].items():\n",
        "        print(f\"    {key}: {value:.6f}\")\n",
        "    \n",
        "    if adf_result[1] <= 0.05:\n",
        "        print(\"  ‚úÖ Series is stationary (reject null hypothesis)\")\n",
        "    else:\n",
        "        print(\"  ‚ùå Series is non-stationary (fail to reject null hypothesis)\")\n",
        "    \n",
        "    # KPSS Test\n",
        "    try:\n",
        "        kpss_result = kpss(timeseries.dropna(), regression='c')\n",
        "        print(f\"\\nKPSS Test:\")\n",
        "        print(f\"  KPSS Statistic: {kpss_result[0]:.6f}\")\n",
        "        print(f\"  p-value: {kpss_result[1]:.6f}\")\n",
        "        print(f\"  Critical Values:\")\n",
        "        for key, value in kpss_result[3].items():\n",
        "            print(f\"    {key}: {value:.6f}\")\n",
        "        \n",
        "        if kpss_result[1] >= 0.05:\n",
        "            print(\"  ‚úÖ Series is stationary (fail to reject null hypothesis)\")\n",
        "        else:\n",
        "            print(\"  ‚ùå Series is non-stationary (reject null hypothesis)\")\n",
        "    except:\n",
        "        print(\"  ‚ö†Ô∏è KPSS test failed (insufficient data or other issue)\")\n",
        "\n",
        "def make_stationary(timeseries, method='diff'):\n",
        "    \"\"\"\n",
        "    Make time series stationary using differencing or log transformation.\n",
        "    \"\"\"\n",
        "    if method == 'diff':\n",
        "        return timeseries.diff().dropna()\n",
        "    elif method == 'log_diff':\n",
        "        return np.log(timeseries + 1).diff().dropna()\n",
        "    elif method == 'log':\n",
        "        return np.log(timeseries + 1)\n",
        "    else:\n",
        "        return timeseries\n",
        "\n",
        "# Test stationarity for key categories\n",
        "key_categories = ['Total', 'Compute', 'Storage', 'Database']\n",
        "stationarity_results = {}\n",
        "\n",
        "for category in key_categories:\n",
        "    if category in forecasting_data:\n",
        "        ts_data = forecasting_data[category]\n",
        "        test_stationarity(ts_data, category)\n",
        "        \n",
        "        # Try different transformations\n",
        "        print(f\"\\n--- Testing transformations for {category} ---\")\n",
        "        \n",
        "        # Original data\n",
        "        test_stationarity(ts_data, f\"{category} (Original)\")\n",
        "        \n",
        "        # First difference\n",
        "        diff_data = make_stationary(ts_data, 'diff')\n",
        "        if len(diff_data) > 10:\n",
        "            test_stationarity(diff_data, f\"{category} (1st Diff)\")\n",
        "        \n",
        "        # Log transformation\n",
        "        log_data = make_stationary(ts_data, 'log')\n",
        "        test_stationarity(log_data, f\"{category} (Log)\")\n",
        "        \n",
        "        # Log + First difference\n",
        "        log_diff_data = make_stationary(ts_data, 'log_diff')\n",
        "        if len(log_diff_data) > 10:\n",
        "            test_stationarity(log_diff_data, f\"{category} (Log + 1st Diff)\")\n",
        "        \n",
        "        stationarity_results[category] = {\n",
        "            'original': ts_data,\n",
        "            'diff': diff_data if len(diff_data) > 10 else None,\n",
        "            'log': log_data,\n",
        "            'log_diff': log_diff_data if len(log_diff_data) > 10 else None\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Auto ARIMA Parameter Selection\n",
        "def find_best_arima_params(timeseries, category_name, max_p=5, max_q=5, max_d=2):\n",
        "    \"\"\"\n",
        "    Find the best ARIMA parameters using auto_arima.\n",
        "    \"\"\"\n",
        "    print(f\"\\nFinding best ARIMA parameters for {category_name}...\")\n",
        "    \n",
        "    try:\n",
        "        # Use auto_arima to find best parameters\n",
        "        model = auto_arima(\n",
        "            timeseries,\n",
        "            start_p=0, start_q=0,\n",
        "            max_p=max_p, max_q=max_q, max_d=max_d,\n",
        "            seasonal=True,\n",
        "            m=7,  # Weekly seasonality\n",
        "            stepwise=True,\n",
        "            suppress_warnings=True,\n",
        "            error_action='ignore',\n",
        "            trace=True\n",
        "        )\n",
        "        \n",
        "        print(f\"Best ARIMA parameters for {category_name}: {model.order}\")\n",
        "        if hasattr(model, 'seasonal_order') and model.seasonal_order:\n",
        "            print(f\"Best seasonal parameters: {model.seasonal_order}\")\n",
        "        \n",
        "        return model\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error finding parameters for {category_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Find best parameters for each category\n",
        "arima_models = {}\n",
        "best_params = {}\n",
        "\n",
        "for category in key_categories:\n",
        "    if category in stationarity_results:\n",
        "        ts_data = stationarity_results[category]['original']\n",
        "        \n",
        "        if len(ts_data) > 50:  # Need sufficient data\n",
        "            model = find_best_arima_params(ts_data, category)\n",
        "            if model:\n",
        "                arima_models[category] = model\n",
        "                best_params[category] = {\n",
        "                    'order': model.order,\n",
        "                    'seasonal_order': getattr(model, 'seasonal_order', None),\n",
        "                    'aic': model.aic(),\n",
        "                    'bic': model.bic()\n",
        "                }\n",
        "        else:\n",
        "            print(f\"Skipping {category} - insufficient data points\")\n",
        "\n",
        "print(f\"\\nSuccessfully found parameters for: {list(arima_models.keys())}\")\n",
        "print(\"\\nBest parameters summary:\")\n",
        "for category, params in best_params.items():\n",
        "    print(f\"{category}: {params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ARIMA Models and Generate Forecasts\n",
        "def train_arima_model(timeseries, order, seasonal_order=None, periods=30):\n",
        "    \"\"\"\n",
        "    Train ARIMA model and generate forecasts.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fit the model\n",
        "        if seasonal_order:\n",
        "            model = SARIMAX(timeseries, order=order, seasonal_order=seasonal_order)\n",
        "        else:\n",
        "            model = ARIMA(timeseries, order=order)\n",
        "        \n",
        "        fitted_model = model.fit(disp=False)\n",
        "        \n",
        "        # Generate forecasts\n",
        "        forecast = fitted_model.forecast(steps=periods)\n",
        "        conf_int = fitted_model.get_forecast(steps=periods).conf_int()\n",
        "        \n",
        "        return fitted_model, forecast, conf_int\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error training model: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Train models and generate forecasts\n",
        "arima_results = {}\n",
        "forecast_periods = 30\n",
        "\n",
        "for category, model in arima_models.items():\n",
        "    print(f\"\\nTraining ARIMA model for {category}...\")\n",
        "    \n",
        "    ts_data = stationarity_results[category]['original']\n",
        "    order = best_params[category]['order']\n",
        "    seasonal_order = best_params[category]['seasonal_order']\n",
        "    \n",
        "    fitted_model, forecast, conf_int = train_arima_model(\n",
        "        ts_data, order, seasonal_order, forecast_periods\n",
        "    )\n",
        "    \n",
        "    if fitted_model is not None:\n",
        "        arima_results[category] = {\n",
        "            'model': fitted_model,\n",
        "            'forecast': forecast,\n",
        "            'conf_int': conf_int,\n",
        "            'order': order,\n",
        "            'seasonal_order': seasonal_order,\n",
        "            'aic': fitted_model.aic,\n",
        "            'bic': fitted_model.bic\n",
        "        }\n",
        "        \n",
        "        print(f\"Model trained successfully for {category}\")\n",
        "        print(f\"Order: {order}, Seasonal: {seasonal_order}\")\n",
        "        print(f\"AIC: {fitted_model.aic:.2f}, BIC: {fitted_model.bic:.2f}\")\n",
        "        print(f\"Forecast mean: ${forecast.mean():.2f}\")\n",
        "        print(f\"Forecast std: ${forecast.std():.2f}\")\n",
        "    else:\n",
        "        print(f\"Failed to train model for {category}\")\n",
        "\n",
        "print(f\"\\nSuccessfully trained models for: {list(arima_results.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Diagnostics and Evaluation\n",
        "def evaluate_arima_model(model, category_name):\n",
        "    \"\"\"\n",
        "    Perform diagnostic tests on ARIMA model.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Model Diagnostics for {category_name} ===\")\n",
        "    \n",
        "    # Model summary\n",
        "    print(\"Model Summary:\")\n",
        "    print(model.summary())\n",
        "    \n",
        "    # Residual analysis\n",
        "    residuals = model.resid\n",
        "    \n",
        "    # Ljung-Box test for residual autocorrelation\n",
        "    lb_test = acorr_ljungbox(residuals, lags=10, return_df=True)\n",
        "    print(f\"\\nLjung-Box Test (p-values):\")\n",
        "    print(lb_test['lb_pvalue'].head())\n",
        "    \n",
        "    # Check if residuals are white noise\n",
        "    if lb_test['lb_pvalue'].min() > 0.05:\n",
        "        print(\"‚úÖ Residuals appear to be white noise (no autocorrelation)\")\n",
        "    else:\n",
        "        print(\"‚ùå Residuals show autocorrelation (model may need improvement)\")\n",
        "    \n",
        "    # Normality test\n",
        "    from scipy import stats\n",
        "    shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
        "    print(f\"\\nShapiro-Wilk normality test:\")\n",
        "    print(f\"Statistic: {shapiro_stat:.6f}, p-value: {shapiro_p:.6f}\")\n",
        "    \n",
        "    if shapiro_p > 0.05:\n",
        "        print(\"‚úÖ Residuals appear to be normally distributed\")\n",
        "    else:\n",
        "        print(\"‚ùå Residuals are not normally distributed\")\n",
        "    \n",
        "    return {\n",
        "        'residuals': residuals,\n",
        "        'ljung_box': lb_test,\n",
        "        'shapiro_stat': shapiro_stat,\n",
        "        'shapiro_p': shapiro_p\n",
        "    }\n",
        "\n",
        "# Evaluate all models\n",
        "model_diagnostics = {}\n",
        "for category, result in arima_results.items():\n",
        "    diagnostics = evaluate_arima_model(result['model'], category)\n",
        "    model_diagnostics[category] = diagnostics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize ARIMA Results\n",
        "def plot_arima_results(timeseries, forecast, conf_int, category_name, periods=30):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations for ARIMA model results.\n",
        "    \"\"\"\n",
        "    # Create future dates\n",
        "    last_date = timeseries.index[-1]\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=periods, freq='D')\n",
        "    \n",
        "    # Create subplots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            f'{category_name} - Historical Data and Forecast',\n",
        "            f'{category_name} - Forecast with Confidence Intervals',\n",
        "            f'{category_name} - Residuals',\n",
        "            f'{category_name} - ACF of Residuals'\n",
        "        ),\n",
        "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "    )\n",
        "    \n",
        "    # 1. Historical data and forecast\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=timeseries.index, y=timeseries.values, mode='lines',\n",
        "                  name='Historical', line=dict(color='blue')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=future_dates, y=forecast, mode='lines',\n",
        "                  name='Forecast', line=dict(color='red')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Forecast with confidence intervals\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=future_dates, y=forecast, mode='lines',\n",
        "                  name='Forecast', line=dict(color='red')),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # Add confidence intervals\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=future_dates, y=conf_int.iloc[:, 1], \n",
        "                  mode='lines', line=dict(width=0), showlegend=False),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=future_dates, y=conf_int.iloc[:, 0], \n",
        "                  mode='lines', line=dict(width=0), fill='tonexty',\n",
        "                  fillcolor='rgba(255,0,0,0.2)', name='95% CI'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Residuals\n",
        "    if category_name in model_diagnostics:\n",
        "        residuals = model_diagnostics[category_name]['residuals']\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=timeseries.index[1:], y=residuals, mode='lines',\n",
        "                      name='Residuals', line=dict(color='green')),\n",
        "            row=2, col=1\n",
        "        )\n",
        "    \n",
        "    # 4. ACF of residuals\n",
        "    if category_name in model_diagnostics:\n",
        "        residuals = model_diagnostics[category_name]['residuals']\n",
        "        from statsmodels.tsa.stattools import acf\n",
        "        acf_values = acf(residuals, nlags=20)\n",
        "        lags = range(len(acf_values))\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Bar(x=list(lags), y=acf_values, name='ACF'),\n",
        "            row=2, col=2\n",
        "        )\n",
        "    \n",
        "    fig.update_layout(height=800, title_text=f\"ARIMA Model Results - {category_name}\")\n",
        "    fig.show()\n",
        "\n",
        "# Create visualizations for each model\n",
        "for category, result in arima_results.items():\n",
        "    ts_data = stationarity_results[category]['original']\n",
        "    plot_arima_results(\n",
        "        ts_data, \n",
        "        result['forecast'], \n",
        "        result['conf_int'], \n",
        "        category, \n",
        "        forecast_periods\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ARIMA Results\n",
        "print(\"=== Saving ARIMA Results ===\")\n",
        "\n",
        "# Save models and results\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create results directory\n",
        "results_dir = '/Users/sabbineni/projects/acm/results/arima'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Save models\n",
        "for category, result in arima_results.items():\n",
        "    model_path = f\"{results_dir}/arima_model_{category.lower()}.pkl\"\n",
        "    joblib.dump(result['model'], model_path)\n",
        "    print(f\"Saved model: {model_path}\")\n",
        "\n",
        "# Save forecasts\n",
        "for category, result in arima_results.items():\n",
        "    # Create forecast DataFrame\n",
        "    last_date = stationarity_results[category]['original'].index[-1]\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), \n",
        "                                periods=forecast_periods, freq='D')\n",
        "    \n",
        "    forecast_df = pd.DataFrame({\n",
        "        'date': future_dates,\n",
        "        'forecast': result['forecast'],\n",
        "        'lower_bound': result['conf_int'].iloc[:, 0],\n",
        "        'upper_bound': result['conf_int'].iloc[:, 1]\n",
        "    })\n",
        "    \n",
        "    forecast_path = f\"{results_dir}/arima_forecast_{category.lower()}.csv\"\n",
        "    forecast_df.to_csv(forecast_path, index=False)\n",
        "    print(f\"Saved forecast: {forecast_path}\")\n",
        "\n",
        "# Save model parameters and diagnostics\n",
        "params_df = pd.DataFrame(best_params).T\n",
        "params_path = f\"{results_dir}/arima_parameters.csv\"\n",
        "params_df.to_csv(params_path)\n",
        "print(f\"Saved parameters: {params_path}\")\n",
        "\n",
        "# Save diagnostics\n",
        "if model_diagnostics:\n",
        "    diagnostics_path = f\"{results_dir}/arima_diagnostics.pkl\"\n",
        "    joblib.dump(model_diagnostics, diagnostics_path)\n",
        "    print(f\"Saved diagnostics: {diagnostics_path}\")\n",
        "\n",
        "# Create forecast comparison\n",
        "forecast_comparison = pd.DataFrame()\n",
        "for category, result in arima_results.items():\n",
        "    last_date = stationarity_results[category]['original'].index[-1]\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), \n",
        "                                periods=forecast_periods, freq='D')\n",
        "    forecast_comparison[category] = result['forecast'].values\n",
        "\n",
        "forecast_comparison.index = future_dates\n",
        "forecast_comparison.index.name = 'Date'\n",
        "\n",
        "comparison_path = f\"{results_dir}/arima_forecast_comparison.csv\"\n",
        "forecast_comparison.to_csv(comparison_path)\n",
        "print(f\"Saved forecast comparison: {comparison_path}\")\n",
        "\n",
        "print(\"\\n‚úÖ ARIMA model implementation completed successfully!\")\n",
        "print(\"üìä Models trained, evaluated, and saved\")\n",
        "print(\"üîÆ Future forecasts generated for 30 days\")\n",
        "print(\"üìà Results ready for comparison with other models\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
